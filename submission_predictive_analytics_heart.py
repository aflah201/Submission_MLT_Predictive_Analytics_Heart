# -*- coding: utf-8 -*-
"""Salinan Submission_Predictive_Analytics_Heart

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16qPMU3bfFoZHGkJVAFP3_XdepPwor_r3

# **Proyek Analitik Prediktif : Kumpulan Data Prediksi Gagal Jantung**

* Nama : Moh. Aflah Azzaky
* Email : aflahazzaki123@gmail.com
* ID Dicoding : aflahazzaky
* Dataset : [Heart Failure Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)

# **Data Understanding**

Data pada project ini menggunakan data yang bersumber pada sebuah situs kaggle, dimana fokus pada data tersebut menjelaskan faktor-faktor yang akan mempengaruhi sebuah penyakit gagal jantung.[[Kaggle Dataset - Heart Failure Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)]

Pada berkas yang diunduh yakni heart.csv berisi 918 rows x 12 columns. Kolom-kolom tersebut berisi diantaranya 1 kolom berisi tipe data `float64`, 6 kolom berisi tipe data `int64`, dan 5 kolom berisi tipe data `object`. Untuk penjelasan mengenai variabel dapat dilihat sebagai berikut:
1. **Age**: usia pasien dalam jumlah tahun dengan tipe data `int64`
2. **Sex**: jenis kelamin pasien dengan kategori M = Male/Pria dan F = Female/Perempuan dengan tipe data object
3. **ChestPainType**: jenis nyeri dada dengan kategori TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic dengan tipe data object
   - *Typical Angina* adalah nyeri dada yang disebabkan oleh aktivitas fisik atau stres emosional, dan berkurang saat istirahat atau mengonsumsi nitrogliserin.
   - *Atypical Angina* adalah nyeri dada yang tidak memenuhi kriteria angina tipikal, tetapi sesuai dengan penyebab iskemik jantung.
   - *Non-Anginal Pain* adalah nyeri dada yang tidak disebabkan oleh penyakit jantung.
   - *Asymptomatic* adalah istilah yang menggambarkan kondisi seseorang yang menderita penyakit, tetapi tidak menunjukkan gejala klinis apa pun.
4. **RestingBP**: tekanan darah istirahat dengan tipe data `int64`.
5. **Cholesterol**: kolesterol serum dengan tipe data `int64`.
6. **FastingBS**: gula darah puasa dengan tipe data `int64`.
7. **RestingECG**: hasil elektrokardiogram istirahat dengan kategori Normal, ST = Mengalami kelainan gelombang ST-T, LVH = menunjukkan kemungkinan atau pasti hipertrofi ventrikel kiri dengan tipe data `object`.
8. **MaxHR**: detak jantung maksimum tercapai dengan tipe data `int64` yang berisi nilai numerik antara 60 dan 202.
9. **ExerciseAngina**: angina akibat olahraga dengan kategori Y = Yes/Iya & N = No/Tidak bertipe data `object`.
10. **Oldpeak**: puncak tua nilai numerik yang diukur pada depresi bertipe data `float64`.
11. **ST_Slope**: kemiringan segmen ST terhadap denyut jantung (heart rate) yang dihitung dengan linear regression dengan kategori Up: upsloping, Flat: flat, Down: downsloping bertipe data `object`.
12. **HeartDisease**: penyakit jantung dengan hasil keluaran 1 = penyakit jantung dan 0 = normal bertipe data `int64`.

# **Data Loading**

## ***Install & Import Library***

* *Libray* Numpy digunakan untuk memproses larik atau array.
* *Libray* Matplotlib digunakan membuat visualisasi data dalam dua dimensi.
* *Libray* Seaborn dibangun di ata *library* Matplotlib, digunakan untuk membuat visualisasi data.
* *Libray* Pandas digunakan untuk menganalisis dan memanipulasi data.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score

import warnings
warnings.filterwarnings('ignore')

# %matplotlib inline

"""## ***Read Dataset From Kaggle***

1. Menginstall kaggle dan mengunduh dataset menggunakan *Command API Kaggle*.
"""

!pip install kaggle

os.environ['KAGGLE_KEY'] = 'bb18e594229a6d36e6251ef61baea580'
os.environ['KAGGLE_USERNAME'] = 'aflahazzaky'

!kaggle datasets download -d fedesoriano/heart-failure-prediction
!unzip heart-failure-prediction.zip

"""2. Membaca dataset yang telah terunduh dan tersimpan pada file local google colab."""

url = '/content/heart.csv'
df = pd.read_csv(url)
df.head()

"""# **Exploratory Data Analysis**

1. Mendeskripsikan variabel.

## ***Variable Description***

1. Usia: usia pasien [tahun]
2. Jenis Kelamin: jenis kelamin pasien [L: Laki-laki, P: Perempuan]
3. ChestPainType: tipe nyeri dada [TA: Angina Khas, ATA: Angina Atipikal, NAP: Nyeri Non-Anginal, ASY: Tanpa Gejala]
4. RestingBP: tekanan darah istirahat [mm Hg]
5. Kolesterol: kolesterol serum [mm/dl]
6. FastingBS: gula darah puasa [1: jika FastingBS > 120 mg/dl, 0: sebaliknya]
7. RestingECG: hasil elektrokardiogram istirahat [Normal: Normal, ST: mengalami kelainan gelombang ST-T (inversi gelombang T dan/atau elevasi atau depresi ST > 0,05 mV), LVH: menunjukkan kemungkinan atau pasti hipertrofi ventrikel kiri menurut kriteria Estes]
8. MaxHR: detak jantung maksimum tercapai [Nilai numerik antara 60 dan 202]
9. LatihanAngina: angina akibat olahraga [Y: Ya, N: Tidak]
10. Oldpeak: oldpeak = ST [Nilai numerik diukur dalam depresi]
11. ST_Slope : kemiringan puncak latihan segmen ST [Atas : menanjak, Datar : datar, Bawah : miring]
12. Penyakit Jantung: kelas keluaran [1: penyakit jantung, 0: Normal]
"""

df.info()

"""2. Mendeskripsikan statistika dataset."""

df.describe()

"""## ***Handling Missing Values ​​& Outliers***

1. Mengecek nilai 0 pada dataset.
"""

RestingBP = (df.RestingBP == 0).sum()
Cholesterol = (df.Cholesterol == 0).sum()

print(f'Jumlah nilai 0 pada RestingBP: {RestingBP}')
print(f'Jumlah nilai 0 pada Cholesterol: {Cholesterol}')

"""2. Mengecek data yang berisi nilai 0 pada dataset"""

df.loc[(df['RestingBP']==0)]
df.loc[(df['Cholesterol']==0)]

"""3. Menghapus baris data yang berisi nilai 0 pada dataset dengan ketentuan kolom yang dipilih."""

df.drop(df.loc[(df['RestingBP']==0)].index, inplace=True)
df.drop(df.loc[(df['Cholesterol']==0)].index, inplace=True)
df.shape

"""4. Mendeskripiskan statistik dataset."""

df.describe()

"""5. Menghapus kolom data yang tidak diperlukan."""

df.drop(['FastingBS'], axis=1, inplace=True)
df.head()

"""6. Menampilkan outliers 'RestingBP'."""

sns.boxplot(x=df['RestingBP'])

"""7. Menampilkan outliers 'Cholesterol'."""

sns.boxplot(x=df['Cholesterol'])

"""8. Menampilkan outliers 'Oldpeak'."""

sns.boxplot(x=df['Oldpeak'])

"""Dari boxplot diatas, kita dapat mengidentifikasi **outliers** (pencilan) dalam data:

1. **Garis tengah kotak** menunjukkan **median** dari data `'RestingBP','Cholesterol', 'Oldpeak'`.
2. **Kotak** menunjukkan rentang dari **kuartil pertama (Q1)** hingga **kuartil ketiga (Q3)**, menggambarkan **interquartile range (IQR)**, yaitu rentang tengah 50% dari data.
3. **Garis-garis horizontal** (whiskers) yang keluar dari kotak menunjukkan rentang data di luar Q1 dan Q3, umumnya diperpanjang hingga 1,5 kali IQR dari kuartil terendah (Q1) dan tertinggi (Q3).
4. **Titik-titik** di luar whiskers adalah **outliers**. Titik-titik ini mewakili nilai yang berada di luar rentang 1,5 kali IQR dari Q1 dan Q3, menandakan nilai `'RestingBP','Cholesterol', 'Oldpeak'` yang jauh dari mayoritas data.

9. Membatasi nilai outliers.
"""

df_numeric = df.select_dtypes(include=[np.number])
Q1 = df_numeric.quantile(0.25)
Q3 = df_numeric.quantile(0.75)
IQR=Q3-Q1
df_cleaned=df[~((df_numeric<(Q1-1.5*IQR))|(df_numeric>(Q3+1.5*IQR))).any(axis=1)]

# Cek ukuran dataset setelah kita drop outliers
df_cleaned.shape

"""10. Menampilkan dataset yang telah dibersihkan."""

df_cleaned.info()

"""## ***Univariate Analysis***

1. Membagi 2 bagian yaitu data kategori dan numerik
"""

categorical_features = df.select_dtypes(include=['object']).columns
numerical_features = df.select_dtypes(include=['int64', 'float64']).columns

"""### Categorical Features

2. Menampilkan plot kategori
"""

feature = categorical_features[0]
count = df_cleaned[feature].value_counts()
percent = 100*df_cleaned[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

"""* **Sex**: Kategori M memiliki jumlah sampel yang lebih tinggi dibandingkan kategori F."""

feature = categorical_features[1]
count = df_cleaned[feature].value_counts()
percent = 100*df_cleaned[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

"""* **ChestPainType**: Kategori ASY memiliki frekuensi tertinggi, diikuti oleh kategori NAP dan ATA, sedangkan kategori TA memiliki frekuensi paling rendah. Ini menunjukkan distribusi tipe nyeri dada yang dialami oleh pasien dalam dataset."""

feature = categorical_features[2]
count = df_cleaned[feature].value_counts()
percent = 100*df_cleaned[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

"""* **RestingECG**: Kategori Normal memiliki frekuensi tertinggi, diikuti oleh kategori LVH dan ST. Ini menunjukkan hasil pemeriksaan EKG saat istirahat, di mana kategori tertentu lebih dominan dibandingkan lainnya."""

feature = categorical_features[3]
count = df_cleaned[feature].value_counts()
percent = 100*df_cleaned[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

"""* **ExerciseAngina**: Kategori N lebih tinggi daripada kategori Y, yang menunjukkan bahwa lebih banyak sampel yang tidak mengalami angina saat latihan dibandingkan yang mengalaminya."""

feature = categorical_features[4]
count = df_cleaned[feature].value_counts()
percent = 100*df_cleaned[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)

"""* **ST_Slope**: Kategori Flat dan Down memiliki jumlah sampel yang hampir sama dan dominan, sementara kategori Up memiliki jumlah sampel yang jauh lebih sedikit. Ini menggambarkan pola kemiringan segmen ST setelah latihan.

### Numerical Features

3. Menampilkan plot numerik
"""

df_cleaned.hist(bins=50, figsize=(20,15))
plt.show()

"""## ***Multivariate Analysis***

1. Mengecek rata-rata terhadap masing-masing fitur untuk mengetahui pengaruh fitur kategori.

### Categorical Features
"""

cat_features = df_cleaned.select_dtypes(include=['object']).columns.tolist()

for col in cat_features:
    sns.catplot(x=col, y="Age", kind="bar", dodge=False, height = 4, aspect = 3,  data=df_cleaned, palette="Set3")
    plt.title("Average 'Age' Relative to - {}".format(col))

cat_features = df_cleaned.select_dtypes(include=['object']).columns.tolist()

for col in cat_features:
    sns.catplot(x=col, y="RestingBP", kind="bar", dodge=False, height = 4, aspect = 3,  data=df_cleaned, palette="Set3")
    plt.title("Average 'RestingBP' Relative to - {}".format(col))

cat_features = df_cleaned.select_dtypes(include=['object']).columns.tolist()

for col in cat_features:
    sns.catplot(x=col, y="Cholesterol", kind="bar", dodge=False, height = 4, aspect = 3,  data=df_cleaned, palette="Set3")
    plt.title("Average 'Cholesterol' Relative to - {}".format(col))

cat_features = df_cleaned.select_dtypes(include=['object']).columns.tolist()

for col in cat_features:
    sns.catplot(x=col, y="MaxHR", kind="bar", dodge=False, height = 4, aspect = 3,  data=df_cleaned, palette="Set3")
    plt.title("Average 'MaxHR' Relative to - {}".format(col))

cat_features = df_cleaned.select_dtypes(include=['object']).columns.tolist()

for col in cat_features:
    sns.catplot(x=col, y="Oldpeak", kind="bar", dodge=False, height = 4, aspect = 3,  data=df_cleaned, palette="Set3")
    plt.title("Average 'Oldpeak' Relative to - {}".format(col))

cat_features = df_cleaned.select_dtypes(include=['object']).columns.tolist()

for col in cat_features:
    sns.catplot(x=col, y="HeartDisease", kind="bar", dodge=False, height = 4, aspect = 3,  data=df_cleaned, palette="Set3")
    plt.title("Average 'HeartDisease' Relative to - {}".format(col))

"""### Numerical Features

2. Menampilkan hubungan fitur numerik.
"""

sns.pairplot(df_cleaned, hue = 'HeartDisease')
# sns.pairplot(df_cleaned, diag_kind = 'kde')

"""### Correlation Matrix

3. Menampikan korelasi
"""

plt.figure(figsize=(10,8))
correlation_matrix = df_cleaned[numerical_features].corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Matriks korelasi ini menggambarkan seberapa kuat hubungan antara fitur-fitur numerik dalam dataset yang berkaitan dengan penyakit jantung. Mari kita lihat satu per satu dengan lebih sederhana:

1. **Umur (Age)**:
   - Ada hubungan positif dengan penyakit jantung (korelasi 0.31). Ini artinya, semakin tua seseorang, semakin besar kemungkinan dia punya penyakit jantung.
   - Ada juga hubungan negatif dengan `MaxHR` (detak jantung maksimal saat olahraga), sebesar -0.41. Ini berarti semakin tua seseorang, detak jantung maksimalnya cenderung lebih rendah.

2. **Tekanan Darah Istirahat (RestingBP)**:
   - Ada sedikit hubungan positif dengan penyakit jantung (0.17). Ini menunjukkan kalau tekanan darah istirahat yang lebih tinggi sedikit berhubungan dengan risiko penyakit jantung.
   - Tekanan darah juga ada hubungannya dengan usia (0.27), jadi semakin tua, biasanya tekanan darah istirahat bisa naik sedikit.

3. **Kolesterol**:
   - Fitur ini hampir tidak ada hubungannya dengan penyakit jantung (korelasi cuma 0.09). Jadi, kadar kolesterol di dataset ini mungkin bukan faktor utama untuk menentukan risiko penyakit jantung.
   - Hubungan dengan fitur lain juga sangat lemah, jadi kolesterol tampaknya kurang berpengaruh dalam kasus ini.

4. **Detak Jantung Maksimal (MaxHR)**:
   - Ada hubungan negatif dengan penyakit jantung (-0.39). Artinya, detak jantung maksimal yang lebih rendah cenderung dihubungkan dengan risiko penyakit jantung yang lebih tinggi.
   - Juga ada hubungan negatif dengan umur (-0.41), yang menunjukkan bahwa seiring bertambahnya usia, detak jantung maksimal kita biasanya menurun.

5. **Oldpeak (Penurunan ST setelah olahraga)**:
   - Ini fitur yang punya hubungan paling kuat dengan penyakit jantung (0.5). Jadi, semakin tinggi penurunan ST ini, makin besar peluang seseorang mengalami penyakit jantung.
   - Oldpeak juga ada hubungannya dengan `MaxHR` (-0.28), menunjukkan bahwa nilai Oldpeak cenderung lebih tinggi kalau detak jantung maksimal menurun.

Secara keseluruhan, fitur yang paling berpengaruh terhadap penyakit jantung adalah `Oldpeak`, diikuti oleh `MaxHR` dan `Umur`, sementara fitur seperti `Kolesterol` kelihatannya tidak terlalu berpengaruh di sini.

# **Data Preparation**

## ***Category Feature Encoding***
"""

df_cleaned = pd.concat([df_cleaned, pd.get_dummies(df_cleaned['Sex'], prefix='Sex', dtype='int')], axis=1)
df_cleaned = pd.concat([df_cleaned, pd.get_dummies(df_cleaned['ChestPainType'], prefix='ChestPainType', dtype='int')], axis=1)
df_cleaned = pd.concat([df_cleaned, pd.get_dummies(df_cleaned['RestingECG'], prefix='RestingECG', dtype='int')], axis=1)
df_cleaned = pd.concat([df_cleaned, pd.get_dummies(df_cleaned['ExerciseAngina'], prefix='ExerciseAngina', dtype='int')], axis=1)
df_cleaned = pd.concat([df_cleaned, pd.get_dummies(df_cleaned['ST_Slope'], prefix='ST_Slope', dtype='int')], axis=1)
df_cleaned.drop(['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope'], axis=1, inplace=True)
df_cleaned.head()

df_cleaned.info()

"""## ***Train Test Spilt***

* Split dataset menjadi data train dan data test sebelum transformasi (supaya transformasi diterapkan hanya pada data latih)
"""

X = df_cleaned.drop(["HeartDisease"],axis =1)
y = df_cleaned["HeartDisease"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## ***Standardization***

* Standarisasi fitur dengan cara mengurangi setiap nilai pada kumpulan data dengan nilai rata-rata, kemudian dibagi dengan deviasi standar. Standarisasi ditujukan supaya data tidak memiliki penyimpangan nilai yang besar.
"""

num_features = ['Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']

scaler = StandardScaler()
scaler.fit(X_train[num_features])
X_train[num_features] = scaler.transform(X_train.loc[:, num_features])
X_train[num_features].head()

num_features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
X_train[num_features].describe().round(4)

"""Perhatikan tabel di atas, sekarang nilai mean = 0 dan standar deviasi = 1.

# **Model Development**

1. Menyiapkan dataframe untuk analisis model
"""

models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""## ***Model Development MSE***

### ***Model Development with K-Nearest Neighbor***
"""

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','KNN'] = mean_squared_error(y_pred=knn.predict(X_train), y_true=y_train)

"""### ***Model Development with Random Forest***"""

RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""### ***Model Development with Boosting Algorithm***"""

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""## ***Model Development Classifier***

### ***Model Development with K-Nearest Neighbor***
"""

knn_classifier = KNeighborsClassifier(n_neighbors=10)
knn_classifier.fit(X_train, y_train)

"""### ***Model Development with Random Forest***"""

rf_classifier = RandomForestClassifier(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
rf_classifier.fit(X_train, y_train)

"""### ***Model Development with Boosting***"""

boost_classifier = AdaBoostClassifier(learning_rate=0.05, random_state=55)
boost_classifier.fit(X_train, y_train)

"""### ***Implementation Random Search***"""

knn_random_search = KNeighborsClassifier()
knn_param_dist = {
    'n_neighbors': [3, 5, 7, 9, 11, 13, 15],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}
knn_random_search = RandomizedSearchCV(knn_random_search, knn_param_dist, cv=5, n_iter=10, scoring='accuracy')
knn_random_search.fit(X_train, y_train)

rf_random_search = RandomForestClassifier()
rf_param_dist = {
    'n_estimators': [50, 100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}
rf_random_search = RandomizedSearchCV(rf_random_search, rf_param_dist, cv=5, n_iter=10, scoring='accuracy')
rf_random_search.fit(X_train, y_train)

boost_random_search = AdaBoostClassifier()
boost_param_dist = {
    'n_estimators': [50, 100, 150, 200],
    'learning_rate': [0.01, 0.05, 0.1, 0.2]
}
boost_random_search = RandomizedSearchCV(boost_random_search, boost_param_dist, cv=5, n_iter=10, scoring='accuracy')
boost_random_search.fit(X_train, y_train)

print("Best parameters for KNN:", knn_random_search.best_params_)
print("Best parameters for Random Forest:", rf_random_search.best_params_)
print("Best parameters for Boosting:", boost_random_search.best_params_)
print("-------------------------------")
print("Best score for KNN:", knn_random_search.best_score_)
print("Best score for Random Forest:", rf_random_search.best_score_)
print("Best score for Boosting:", boost_random_search.best_score_)

"""## ***Model Development Testing***

### ***Model MSE***
"""

knn_pred = knn.predict(X_test)
RF_pred = RF.predict(X_test)
boosting_pred = boosting.predict(X_test)

print(f'MSE KNN: {mean_squared_error(y_test, knn_pred)}')
print(f'MSE Random Forest: {mean_squared_error(y_test, RF_pred)}')
print(f'MSE Boosting: {mean_squared_error(y_test, boosting_pred)}')

"""### ***Model Classifier***"""

knn_classifier_pred = knn_classifier.predict(X_test)
RF_classifier_pred = rf_classifier.predict(X_test)
boosting_classifier_pred = boost_classifier.predict(X_test)

print(f'Akurasi KNN Classifier: {accuracy_score(y_test, knn_classifier_pred)}')
print(f'Akurasi Random Forest Classifier: {accuracy_score(y_test, RF_classifier_pred)}')
print(f'Akurasi Boosting Classifier: {accuracy_score(y_test, boosting_classifier_pred)}')
print('----------------------------------------')
print(f'Presisi KNN Classifier: {precision_score(y_test, knn_classifier_pred)}')
print(f'Presisi Random Forest Classifier: {precision_score(y_test, RF_classifier_pred)}')
print(f'Presisi Boosting Classifier: {precision_score(y_test, boosting_classifier_pred)}')
print('----------------------------------------')
print(f'Recall KNN Classifier: {recall_score(y_test, knn_classifier_pred)}')
print(f'Recall Random Forest Classifier: {recall_score(y_test, RF_classifier_pred)}')
print(f'Recall Boosting Classifier: {recall_score(y_test, boosting_classifier_pred)}')
print('----------------------------------------')
print(f'F1-Score KNN Classifier: {f1_score(y_test, knn_classifier_pred)}')
print(f'F1-Score Random Forest Classifier: {f1_score(y_test, RF_classifier_pred)}')
print(f'F1-Score Boosting Classifier: {f1_score(y_test, boosting_classifier_pred)}')

"""# **Model Evaluation**

### ***Metrics Comparison***
"""

metrics_knn = pd.DataFrame({
    'Accuracy': [accuracy_score(y_test, knn_classifier_pred)],
    'Precision': [precision_score(y_test, knn_classifier_pred)],
    'Recall': [recall_score(y_test, knn_classifier_pred)],
    'F1-Score': [f1_score(y_test, knn_classifier_pred)]}, index=['KNN'])

metrics_rf = pd.DataFrame({
    'Accuracy': [accuracy_score(y_test, RF_classifier_pred)],
    'Precision': [precision_score(y_test, RF_classifier_pred)],
    'Recall': [recall_score(y_test, RF_classifier_pred)],
    'F1-Score': [f1_score(y_test, RF_classifier_pred)]}, index=['RF'])

metrics_boosting = pd.DataFrame({
    'Accuracy': [accuracy_score(y_test, boosting_classifier_pred)],
    'Precision': [precision_score(y_test, boosting_classifier_pred)],
    'Recall': [recall_score(y_test, boosting_classifier_pred)],
    'F1-Score': [f1_score(y_test, boosting_classifier_pred)]}, index=['BOOSTING'])

metrics = pd.concat([metrics_knn, metrics_rf, metrics_boosting], axis=0)
metrics

"""Berdasarkan tabel komparasi di atas, berikut adalah penjelasan dari hasil evaluasi tiga algoritma, yaitu **K-Nearest Neighbors (KNN)**, **Random Forest (RF)**, dan **Boosting**:

1. **KNN (K-Nearest Neighbors)**  
   - **Akurasi:** 89.21%  
   - **Presisi:** 89.86%  
   - **Recall:** 88.57%  
   - **F1-Score:** 89.21%  

   **KNN** menunjukkan kinerja tertinggi secara keseluruhan. Akurasi dan F1-Score yang lebih tinggi menandakan bahwa KNN mampu memprediksi kelas dengan baik dan seimbang antara precision dan recall.

2. **RF (Random Forest)**  
   - **Akurasi:** 88.49%  
   - **Presisi:** 87.50%  
   - **Recall:** 90.00%  
   - **F1-Score:** 88.73%  

   **Random Forest** memiliki **Recall** paling tinggi (90%). Ini berarti RF lebih baik dalam mengidentifikasi kasus positif dengan benar, namun sedikit kalah dalam akurasi dan F1-Score dibandingkan KNN. Jika aplikasi memerlukan fokus pada deteksi positif yang tinggi (misalnya deteksi penyakit), RF bisa menjadi pilihan yang baik.

3. **Boosting**  
   - **Akurasi:** 84.17%  
   - **Presisi:** 88.71%  
   - **Recall:** 78.57%  
   - **F1-Score:** 83.33%  

   **Boosting** memiliki performa terendah dalam hal akurasi dan F1-Score. Meskipun presisinya tinggi (88.71%), **Recall** relatif rendah (78.57%). Ini menunjukkan bahwa Boosting lebih sering melewatkan kasus positif dibandingkan model lainnya.  

### **Kesimpulan:**
- **KNN** memberikan kinerja terbaik secara keseluruhan karena memiliki keseimbangan antara akurasi, precision, dan recall.
- **Random Forest** unggul dalam hal **Recall**, sehingga cocok jika prioritas adalah meminimalkan false negative.
- **Boosting** meskipun memiliki presisi tinggi, kurang optimal dalam menangkap semua kasus positif (recall rendah).

### ***Evaluation MSE***
"""

X_test.loc[:, num_features] = scaler.transform(X_test[num_features])

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))

# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Gambar di atas menunjukkan hasil evaluasi dari tiga model machine learning: Random Forest (RF), K-Nearest Neighbors (KNN), dan Boosting. Grafik tersebut membandingkan performa model pada data training dan testing dalam bentuk bar horizontal. Berikut penjelasan dari setiap model:

1. **Boosting**:
   - Performa pada data training (warna biru) dan testing (warna oranye) sangat mirip dan tinggi, menunjukkan bahwa model ini memiliki kemampuan generalisasi yang baik. Tidak ada tanda overfitting atau underfitting yang signifikan.

2. **KNN**:
   - Performa pada data training dan testing hampir sama seperti Boosting. Nilai pada kedua dataset ini juga tinggi dan konsisten. Hal ini menunjukkan bahwa KNN cukup efektif dalam memprediksi data baru tanpa overfitting.

3. **Random Forest (RF)**:
   - Pada model ini, terlihat perbedaan yang cukup signifikan antara performa pada data training dan testing. Performa pada data training jauh lebih rendah dibandingkan dengan testing, yang mungkin menunjukkan bahwa model ini mengalami underfitting atau memiliki performa yang kurang optimal pada data training.

Secara keseluruhan, Boosting dan KNN menunjukkan performa yang lebih baik dan stabil dibandingkan dengan RF. Boosting dan KNN sepertinya merupakan pilihan yang lebih baik untuk dataset ini.
"""

prediksi = X_test.iloc[:1].copy()
pred_dict = {'HeartDisease':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Hasil prediksi yang paling mendekati nilai asli didapatkan oleh algoritma KNN.

### ***Evaluation Classifier***
"""

metrics = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

model_dict = {'KNN': knn_classifier, 'RF': rf_classifier, 'Boosting': boost_classifier}

for name, model in model_dict.items():
    metrics.loc[name, 'train'] = model.score(X_train, y_train)
    metrics.loc[name, 'test'] = model.score(X_test, y_test)

metrics.sort_values(by='test', ascending=False)

knn_cm = confusion_matrix(y_test, knn_classifier_pred)
rf_cm = confusion_matrix(y_test, RF_classifier_pred)
boost_cm = confusion_matrix(y_test, boosting_classifier_pred)

def plot_cm(confusion_matrix, model_name, color):
  fig, axes = plt.subplots(1, 3, figsize=(18, 5))

  for i, (matrix, name, color) in enumerate(zip(confusion_matrix, model_name, color)):
    sns.heatmap(matrix, annot=True, fmt='g', cmap=color, ax=axes[i])
    axes[i].set_title(f'{name} Confusion Matrix')
    axes[i].set_xlabel('Predicted')
    axes[i].set_ylabel('Actual')

  plt.tight_layout()
  plt.show()

cm = [knn_cm, rf_cm, boost_cm]
model_name = ['KNN', 'Random Forest', 'Boosting']
color = ['Reds', 'Greens', 'Blues']
plot_cm(cm, model_name, color)

"""Hasil plot di atas menunjukkan matriks kebingungan (confusion matrix) dari tiga model klasifikasi yang berbeda: KNN, Random Forest, dan Boosting. Setiap matriks menggambarkan seberapa baik masing-masing model memprediksi kelas data berdasarkan data aktual. Berikut penjelasan dari setiap plot:

1. **KNN Confusion Matrix (Merah)**:
   - Matriks ini menunjukkan bahwa model KNN memprediksi dengan benar sebanyak **65** kasus untuk kelas 0 dan **10** kasus untuk kelas 1.
   - Namun, model ini juga salah memprediksi sebanyak **4** kasus dari kelas 0 menjadi kelas 1 dan **60** kasus dari kelas 1 menjadi kelas 0.
   - Ini menunjukkan bahwa model KNN memiliki performa yang tidak terlalu baik, terutama dalam memprediksi kelas 1, karena banyak prediksi salah pada kelas tersebut.

2. **Random Forest Confusion Matrix (Hijau)**:
   - Matriks ini menunjukkan bahwa model Random Forest memprediksi dengan benar sebanyak **59** kasus untuk kelas 0 dan **41** kasus untuk kelas 1.
   - Kesalahan terjadi pada **10** kasus dari kelas 0 yang diprediksi menjadi kelas 1 dan **29** kasus dari kelas 1 yang diprediksi menjadi kelas 0.
   - Model ini memiliki akurasi yang lebih baik dibandingkan KNN, terutama karena lebih sedikit kesalahan dalam memprediksi kelas 1.

3. **Boosting Confusion Matrix (Biru)**:
   - Pada model Boosting, sebanyak **59** kasus dari kelas 0 dan **58** kasus dari kelas 1 diprediksi dengan benar.
   - Kesalahan terjadi pada **10** kasus dari kelas 0 yang diprediksi menjadi kelas 1 dan **12** kasus dari kelas 1 yang diprediksi menjadi kelas 0.
   - Ini adalah model yang paling akurat di antara ketiga model tersebut, dengan distribusi kesalahan yang lebih sedikit, terutama dalam memprediksi kelas 1.

**Kesimpulan**: Dari ketiga model di atas, **Boosting** memiliki performa terbaik dengan jumlah prediksi benar yang paling tinggi dan jumlah kesalahan yang paling rendah. Model **Random Forest** berada di posisi kedua, sementara **KNN** memiliki performa yang paling rendah, terutama dalam memprediksi kelas 1.
"""